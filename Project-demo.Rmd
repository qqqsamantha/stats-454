---
title: "Project demo"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(tidybayes)
library(tidymodels)
library(rstan)
library(rstanarm)
library(bayesplot)
library(bayesrules)
library(broom.mixed)
library(pracma)
library(probably)
hotel <- read.csv("https://raw.githubusercontent.com/yiyangshi-hub/STAT454-Project/main/hotel_bookings.csv")
```

```{r}
hotel_clean <- hotel %>% 
  select(-reservation_status, -reservation_status_date,-company, -arrival_date_day_of_month, -days_in_waiting_list, -agent) %>% 
  filter(country %in%
           c("AUT","BEL","BRA","CHE","CHN","CN","DEU","ESP","FRA","GBR","IRL",
             "ISR","ITA","NLD","NOR","POL","PRT","RUS","SWE","USA")) %>% 
  na.omit()


# random sample 1000 rows from the big dataframe 'hotel'
set.seed(123)
hotel_sub <- sample_n(hotel_clean, 1000)
```

```{r}
hotel_sub%>%
  head()
```

```{r}
# set.seed(123)
# logistic_model_1 <- stan_glm(
#   is_canceled ~. , data = hotel_sub,
#   family = binomial,
#   chains = 4, iter = 5000*2, seed = 123, refresh = 0)
```

```{r}
set.seed(123)

data_cv10 <- vfold_cv(hotel_sub, v = 10)


# Logistic LASSO Regression Model Spec
logistic_lasso_spec_tune <- logistic_reg() %>%
    set_engine('glmnet') %>%
    set_args(mixture = 1, penalty = tune()) %>%
    set_mode('classification')

# Recipe
logistic_rec <- recipe(is_canceled ~ ., data = hotel_sub) %>%
    step_normalize(all_numeric_predictors()) %>% 
    step_dummy(all_nominal_predictors()) %>%  
    step_nzv(all_predictors()) %>% 
    step_corr(all_predictors()) %>% 
    step_mutate(is_canceled = factor(is_canceled))
    # factor more categorical variables later on


# Workflow (Recipe + Model)
log_lasso_wf <- workflow() %>% 
    add_recipe(logistic_rec) %>%
    add_model(logistic_lasso_spec_tune) 


# Tune Model
penalty_grid <- grid_regular(
  penalty(range = c(-5,1)), #log10 transformed  (kept moving min down from 0)
  levels = 30)

tune_output <- tune_grid( 
  log_lasso_wf,
  resamples = data_cv10,
  metrics = metric_set(roc_auc,accuracy),
  control = control_resamples(save_pred = TRUE, event_level = 'second'),
  grid = penalty_grid 
)

# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_output) + theme_classic()
```

```{r}
best_se_penalty <- 
  select_by_one_std_err(tune_output, 
                        metric = 'roc_auc', 
                        desc(penalty)) 
# choose penalty value based on the largest penalty within 1 se of the highest CV roc_auc
best_se_penalty
```
```{r}
final_fit_se <- finalize_workflow(log_lasso_wf, best_se_penalty) %>% # incorporates penalty value to workflow 
    fit(data = hotel_sub)

final_fit_se %>% tidy()
```

hs_prior
```{r}
#p0 <- 2 # prior guess for the number of relevant variables
#tau0 <- p0/(p-p0) * 1/sqrt(n)
#hs_prior <- hs(df=1, global_df=1, global_scale=tau0)
#t_prior <- student_t(df = 7, location = 0, scale = 2.5)
#post2 <- stan_glm(outcome ~ ., data = diabetes,
                 #family = binomial(link = "logit"), 
                 #prior = hs_prior, prior_intercept = t_prior,
                 #seed = SEED, adapt_delta = 0.9)
```

```{r}
# library(brms)
# library(tidyr)
# library(dplyr)
# library(ggplot2)
# library(bayesplot)
# 
# # Binomial example
# split_structure <- break_up_matrix_term(y ~ x, data = hotel_sub)
# df_binom <- split_structure$data
# formula <- split_structure$formula
# d <- hotel_sub
# n <- nrow(hotel_sub) # 100
# D <- ncol(hotel_sub[, -1]) # 20
# p0 <- 5 # prior guess for the number of relevant variables
# tau0 <- p0/(D-p0) * 1/sqrt(n) # scale for tau 
# 
# priorh <- set_prior("horseshoe(scale_global = tau0, scale_slab=1)", class="b")
# fit2 <- brm(formula, data=hotel_sub, family=bernoulli(), iter=500,  chains=2, prior =  priorh,  
#                   sample_prior = T, control=list(adapt_delta=0.999,max_treedepth = 15), save_all_pars = TRUE, refresh=0)
# vs2 <- cv_varsel(fit2)
# plot(vs2, stats = c('elpd', 'rmse'))
# proj2 <- project(vs2, nterms = 3, ns = 500)
# mcmc_areas(as.matrix(proj2)) +  coord_cartesian(xlim = c(-2, 2))
# 

```


> Piironen and Vehtari (2017), which recommends setting the global_scale argument equal to the ratio of the expected number of non-zero coefficients to the expected number of zero coefficients, divided by the square root of the number of observations.

> warning message:Warning: There were 6 divergent transitions after warmup. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
to find out why this is a problem and how to eliminate them.
Warning: Examine the pairs() plot to diagnose sampling problems

```{r}
# library(dplyr)
# set.seed(123)
# p0 <- 10
# tau0 <- p0/(26-p0) * 1/sqrt(1000)
# hs_prior <- hs(df=1, global_df=1, global_scale=tau0)
# logistic_model_1 <- stan_glm(
#   is_canceled ~. , data = hotel_sub,
#   family = binomial,
#   prior = hs_prior,
#   chains = 4, iter = 500*2, seed = 123, refresh = 0)
```

```{r}
head(hotel_sub)
```
is_canceled~hotel+lead_time+arrival_date_year+arrival_date_month+arrival_date_week_number+stays_in_weekend_nights+stays_in_week_nights+adults+children+babies+meal+country+market_segment+distribution_channel+is_repeated_guest+previous_cancellations+previous_bookings_not_canceled+reserved_room_type+assigned_room_type+booking_changes+deposit_type+customer_type+adr+required_car_parking_spaces+total_of_special_requests
```{r}
p0 <- 8
tau0 <- p0/(26-p0) * 1/sqrt(1000)
hs_prior <- hs(df=1, global_df=1, global_scale=tau0)
t_prior <- student_t(df = 26, location = 0, scale = 2.5)
```

```{r}
round(coef(post2), 8)
```


```{r}
set.seed(123)
post2 <- stan_glm(is_canceled~hotel+lead_time+arrival_date_year+arrival_date_month+arrival_date_week_number+stays_in_weekend_nights+stays_in_week_nights+adults+children+babies+meal+country+market_segment+distribution_channel+is_repeated_guest+previous_cancellations+previous_bookings_not_canceled+reserved_room_type+assigned_room_type+booking_changes+deposit_type+customer_type+adr+required_car_parking_spaces+total_of_special_requests,
                  data = hotel_sub,
                 family = binomial(link = "logit"), 
                 prior = hs_prior, 
                 chains = 2, iter = 500*2, 
                 seed = 123,adapt_delta = 0.9999)
```


```{r}
pplot <- plot(post2, "areas", prob = 0.95, prob_outer = 1)
pplot + geom_vline(xintercept = 0)
```

```{r}
head(hotel_sub)
```

```{r}
round(coef(post2), 8)
```

```{r}
round(posterior_interval(post2, prob = 0.9), 8)
```

```{r}
library(loo)
library(projpred)
```

```{r}
# varsel2 <- cv_varsel(post2, method='forward', nloo = 1000)
```



